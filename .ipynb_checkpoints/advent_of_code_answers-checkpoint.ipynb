{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Day-1:-Report-Repair\" data-toc-modified-id=\"Day-1:-Report-Repair-1\"><strong>Day 1: Report Repair</strong></a></span></li><li><span><a href=\"#Day-2:-Password-Philosophy\" data-toc-modified-id=\"Day-2:-Password-Philosophy-2\"><strong>Day 2: Password Philosophy</strong></a></span></li><li><span><a href=\"#Day-3:-Toboggan-Trajectory---incomplete\" data-toc-modified-id=\"Day-3:-Toboggan-Trajectory---incomplete-3\">Day 3: Toboggan Trajectory - incomplete</a></span></li><li><span><a href=\"#Day-4:-Passport-Processing\" data-toc-modified-id=\"Day-4:-Passport-Processing-4\"><strong>Day 4: Passport Processing</strong></a></span></li><li><span><a href=\"#Day-5:-Binary-Boarding---incomplete\" data-toc-modified-id=\"Day-5:-Binary-Boarding---incomplete-5\"><strong>Day 5</strong>: Binary Boarding - incomplete</a></span></li><li><span><a href=\"#Day-6:-Customs-Customs\" data-toc-modified-id=\"Day-6:-Customs-Customs-6\"><strong>Day 6: Customs Customs</strong></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aschul/Galvanize/practice/Advent_of_Code/data\n"
     ]
    }
   ],
   "source": [
    "cd /Users/aschul/Galvanize/practice/Advent_of_Code/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 1: Report Repair**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value #1: 889, value #2: 1131, product: 1005459'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data\n",
    "data = pd.read_csv('data/day_1_data.txt', header=0)\n",
    "\n",
    "# convert txt data to list\n",
    "expenses = data.values.tolist()\n",
    "\n",
    "# convert list of lists to list\n",
    "expenses_list = []\n",
    "for i in expenses:\n",
    "    expenses_list.append(i[0])\n",
    "\n",
    "def find_sum(expenses_list):\n",
    "    '''\n",
    "    input - list\n",
    "    outputs: \n",
    "    1) two numbers that sum to 2020\n",
    "    2) product of those two numbers\n",
    "    '''\n",
    "    diff_list = []\n",
    "    \n",
    "    for val in expenses_list:\n",
    "        diff_list.append(2020-val)\n",
    "    \n",
    "    for val in expenses_list:\n",
    "        for diff in diff_list:\n",
    "            if val == diff:\n",
    "                diff = 2020-val\n",
    "                return (f'value #1: {val}, value #2: {diff}, product: {val*diff}')\n",
    "            \n",
    "find_sum(expenses_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 2: Password Philosophy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('passwords.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[0, 'values']] = df[0].str.split(':', expand=True)\n",
    "df[[0, 'char']] = df[0].str.split(' ', expand=True)\n",
    "df[[0, 'min']] = df[0].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('passwords.txt', header=None)\n",
    "\n",
    "# split data into columns by delim\n",
    "df[[0, 'values']] = df[0].str.split(':', expand=True)\n",
    "df[[0, 'char']] = df[0].str.split(' ', expand=True)\n",
    "df[[0, 'min']] = df[0].str.split('-', expand=True)\n",
    "\n",
    "# rename columns\n",
    "df = df.rename(columns={0:\"min\", \"values\":\"policy\", \"char\":\"char\", \"min\":\"max\"})\n",
    "\n",
    "# convert df columns to lists\n",
    "char = df['char'].values.tolist()\n",
    "max_v = df['max'].values.tolist()\n",
    "min_v = df['min'].values.tolist()\n",
    "policy = df['policy'].values.tolist()\n",
    "\n",
    "# count values of char in password policy\n",
    "list_count = []\n",
    "for i in range(len(policy)):\n",
    "    list_count.append(policy[i].count(char[i]))\n",
    "\n",
    "# convert max_v and min_v to ints\n",
    "max_int = [int(i) for i in max_v]\n",
    "min_int = [int(i) for i in min_v]\n",
    "\n",
    "# check if count of char is greater than the min or max policy, sum instances of True\n",
    "check = []\n",
    "for i in range(len(policy)):\n",
    "    check.append(list_count[i] >= min_int[i] and list_count[i] <= max_int[i])\n",
    "print(sum(check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: Toboggan Trajectory - incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('data/trees_data.txt', header=None)\n",
    "map = data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in map:\n",
    "    for _ in i:\n",
    "        print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1) loop through each row\n",
    "2) after the third item, test if # is found\n",
    "3a) advance a row\n",
    "3) in new row, take index of previous row, add three\n",
    "4) if any item == #, accum += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in map:\n",
    "    for val in row:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for str in map:\n",
    "    for row in str:\n",
    "        for val in row:\n",
    "            if val == \n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 4: Passport Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aschul/Galvanize/practice/Advent_of_Code'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('day_4_data.txt', header=None, skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import file with empty spaces as delimiter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  data\n",
      "0    byr:1985 eyr:2021 iyr:2011 hgt:175cm pid:16306...\n",
      "1    eyr:2023 hcl:#cfa07d ecl:blu hgt:169cm pid:494...\n",
      "2    ecl:zzz eyr:2036 hgt:109 hcl:#623a2f iyr:1997 ...\n",
      "3    hcl:#18171d ecl:oth pid:266824158 hgt:168cm by...\n",
      "4    byr:1932 ecl:hzl pid:284313291 iyr:2017 hcl:#e...\n",
      "..                                                 ...\n",
      "255  ecl:brn byr:1968 cid:216 hgt:181in hcl:#b6652a...\n",
      "256  ecl:hzl hgt:181cm eyr:1977 byr:2018 pid:527754...\n",
      "257  ecl:grn hcl:#efcc98 byr:1935 eyr:2025 iyr:2018...\n",
      "258  hgt:64in ecl:oth hcl:#18171d pid:105602506 byr...\n",
      "259  eyr:2039 hgt:64ecl:#ab45a8 byr:2009iyr:2025 pi...\n",
      "\n",
      "[260 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def per_section(it, is_delimiter=lambda x: x.isspace()):\n",
    "        ret = []\n",
    "        for line in it:\n",
    "            if is_delimiter(line):\n",
    "                if ret:\n",
    "                    yield ' '.join(ret)\n",
    "                    ret = []\n",
    "            else:\n",
    "                ret.append(line.rstrip())\n",
    "        if ret:\n",
    "            yield ''.join(ret)\n",
    "\n",
    "with open(\"data/day_4_data.txt\") as f:\n",
    "    s = list(per_section(f))\n",
    "    df = pd.DataFrame({'data':s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def passport_processing(file):\n",
    "    '''\n",
    "    0) DONE import data formatted to remove empty lines\n",
    "    1) DONE turn data into a list\n",
    "    2) column of number of fields present\n",
    "    3) if number of fields present == 7: check if cid field is present\n",
    "    4) count records with 8 fields OR 7 fields without cid field\n",
    "    '''\n",
    "    \n",
    "    test = 0\n",
    "    \n",
    "    for passport in s:\n",
    "        if ('ecl' and 'pid' and 'eyr' and 'hcl' and 'byr' and 'iyr' and 'cid' and 'hgt') in passport:\n",
    "            test += 1\n",
    "            \n",
    "    return test\n",
    "    \n",
    "passport_processing('day_4_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 122)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def passport_processing(file):\n",
    "    '''\n",
    "    0) DONE import data formatted to remove empty lines\n",
    "    1) DONE turn data into a list\n",
    "    2) column of number of fields present\n",
    "    3) if number of fields present == 7: check if cid field is present\n",
    "    4) count records with 8 fields OR 7 fields without cid field\n",
    "    '''\n",
    "    \n",
    "    all_8 = 0\n",
    "    all_7 = 0\n",
    "    for passport in s:\n",
    "        if \\\n",
    "        'ecl' in passport and \\\n",
    "        'pid' in passport and \\\n",
    "        'eyr' in passport and \\\n",
    "        'hcl' in passport and \\\n",
    "        'byr' in passport and \\\n",
    "        'iyr' in passport and \\\n",
    "        'cid' in passport and \\\n",
    "        'hgt' in passport:\n",
    "            all_8 += 1\n",
    "            \n",
    "    for passport in s:\n",
    "        if \\\n",
    "        'ecl' in passport and \\\n",
    "        'pid' in passport and \\\n",
    "        'eyr' in passport and \\\n",
    "        'hcl' in passport and \\\n",
    "        'byr' in passport and \\\n",
    "        'iyr' in passport and \\\n",
    "        'cid' not in passport and \\\n",
    "        'hgt' in passport:\n",
    "            all_7 += 1\n",
    "            \n",
    "    return (all_8, all_7)\n",
    "    \n",
    "passport_processing('day_4_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in s:\n",
    "    lines.append(list(line.split(',')))\n",
    "    \n",
    "lines_split = []\n",
    "for lst in lines:\n",
    "    for str in lst:\n",
    "        lines_split.append(str.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1) check each nested list for formatting\n",
    "2) create accumulator to count correct formattings; apply to list of 8\n",
    "3) apply to list of 7\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst in lines_split:\n",
    "    for item in lst:\n",
    "        if \\\n",
    "        'ecl' in item and 'pid' in item and 'eyr' in item and \\\n",
    "        'hcl' in item and 'byr' in item and \\\n",
    "        'iyr' in item and 'cid' in item and 'hgt' in item:\n",
    "            print(true)\n",
    "        elif 'ecl' in item and 'pid' in item and 'eyr' in item and \\\n",
    "        'hcl' in item and 'byr' in item and 'iyr' in item and \\\n",
    "        'cid' not in item and 'hgt' in item:\n",
    "            print(True)\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            break \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 5**: Binary Boarding - incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5 = pd.read_csv('day_5.txt')\n",
    "data_5 = data_5.values.tolist()\n",
    "'''\n",
    "1) start outside - if \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_F = 0\n",
    "accum_B = 0\n",
    "\n",
    "for lst in data_5:\n",
    "    for item in lst:\n",
    "        if item[6] == 'F':\n",
    "            accum_F += 1\n",
    "        else:\n",
    "            accum_B += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1) Create decision tree of if/then statements that goes through the scenarios\n",
    "2) if item[6] = F/B -> assign seat\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('textfile) as file:\n",
    "          data = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 6: Customs Customs** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# imports data as df, with NaNs separating data\n",
    "data_6 = pd.read_csv('day_6.txt', header=None, skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_section(it, is_delimiter=lambda x: x.isspace()):\n",
    "        ret = []\n",
    "        for line in it:\n",
    "            if is_delimiter(line):\n",
    "                if ret:\n",
    "                    yield ' '.join(ret)\n",
    "                    ret = []\n",
    "            else:\n",
    "                ret.append(line.rstrip())\n",
    "        if ret:\n",
    "            yield ''.join(ret)\n",
    "\n",
    "with open(\"day_6.txt\") as f:\n",
    "    data_str = list(per_section(f))\n",
    "    df = pd.DataFrame({'data':data_str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces from each string, sort\n",
    "data_reformat = []\n",
    "for x in data_str:\n",
    "    data_reformat.append(sorted(x.replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate questions in each list\n",
    "data_dedup = []\n",
    "for lst in data_reformat:\n",
    "    data_dedup.append(set(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count questions in each set\n",
    "sums = []\n",
    "for val in data_dedup:\n",
    "    sums.append(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6532\n"
     ]
    }
   ],
   "source": [
    "# sum the questions\n",
    "accum = 0\n",
    "for val in sums:\n",
    "    accum += val\n",
    "print(accum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- To refactor:\n",
    "1) import data differently\n",
    "2) use dictionaries to accumulate values and counts\n",
    "3) sum up counts in dict\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To refactor:\n",
    "1) import data differently -> directly into list\n",
    "2) use dictionary to accumulate values\n",
    "3) sum values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda97b54b0afe5f4f968b0e6a2edab277da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
